{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Task To Do:\n",
        "• Implement the Logistic Function by completing the code or writing your own function.\n",
        "• Make sure you pass the test case."
      ],
      "metadata": {
        "id": "l8Cn1sLftK6g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Q0YgSp2lZmpR"
      },
      "outputs": [],
      "source": [
        "def logistic_function(x):\n",
        "    \"\"\"\n",
        "    Computes the logistic function applied to any value of x.\n",
        "    Arguments:\n",
        "    x: scalar or numpy array of any size.\n",
        "    Returns:\n",
        "    y: logistic function applied to x.\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    y = 1 / (1 + np.exp(-x))\n",
        "    return y\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def test_logistic_function():\n",
        "  \"\"\"\n",
        "  Test cases for the logistic_function.\n",
        "  \"\"\"\n",
        "  # Test with scalar input\n",
        "  x_scalar = 0\n",
        "  expected_output_scalar = round(1 / (1 + np.exp(0)), 3) # Expected output: 0.5\n",
        "  assert round(logistic_function(x_scalar), 3) == expected_output_scalar, \"Test failed for scalar input\"\n",
        "  # Test with positive scalar input\n",
        "  x_pos = 2\n",
        "  expected_output_pos = round(1 / (1 + np.exp(-2)), 3) # Expected output: ~0.881\n",
        "  assert round(logistic_function(x_pos), 3) == expected_output_pos, \"Test failed for positive scalar input\"\n",
        "  # Test with negative scalar input\n",
        "  x_neg = -3\n",
        "  expected_output_neg = round(1 / (1 + np.exp(3)), 3) # Expected output: ~0.047\n",
        "  assert round(logistic_function(x_neg), 3) == expected_output_neg, \"Test failed for negative scalar input\"\n",
        "\n",
        "# 4 5CS037 Worksheet - 6:Implementation of Sigmoid Regression from Scratch. Siman Giri\n",
        "\n",
        "# Test with numpy array input\n",
        "x_array = np.array([0, 2, -3])\n",
        "expected_output_array = np.array([0.5, 0.881, 0.047]) # Adjusted expected values rounded to 3 decimals\n",
        "# Use np.round to round the array element-wise and compare\n",
        "assert np.all(np.round(logistic_function(x_array), 3) == expected_output_array), \"Test failed for numpy array input\"\n",
        "print(\"All tests passed!\")\n",
        "# Run the test case\n",
        "test_logistic_function()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9puXg8luV04",
        "outputId": "b9a7cb08-aecb-42b4-c948-cda7e4870245"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task To Do:\n",
        "• Implement the Log - loss Function by completing the code or writing your own function.\n",
        "• Make sure you pass the test case."
      ],
      "metadata": {
        "id": "UFd9sUzjrEL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Computes log loss for true target value y ={0 or 1} and predicted target value y’ inbetween {0-1}.\n",
        "    Arguments:\n",
        "    y_true (scalar): true target value {0 or 1}.\n",
        "    y_pred (scalar): predicted taget value {0-1}.\n",
        "    Returns:\n",
        "    loss (float): loss/error value\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "\n",
        "    # Ensure y_pred is clipped to avoid log(0)\n",
        "    y_pred = np.clip(y_pred, 1e-10, 1 - 1e-10)\n",
        "\n",
        "    loss = -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "nOjOOF8fpDTg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verifying the Intuition:"
      ],
      "metadata": {
        "id": "lnp7LDVcrlzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test function:\n",
        "y_true, y_pred = 0, 0.1\n",
        "print(f'log loss({y_true}, {y_pred}) ==> {log_loss(y_true, y_pred)}')\n",
        "print(\"+++++++++++++--------------------------++++++++++++++++++++++++\")\n",
        "y_true, y_pred = 1, 0.9\n",
        "print(f'log loss({y_true}, {y_pred}) ==> {log_loss(y_true, y_pred)}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKgs1Wq8qU2o",
        "outputId": "149aa6dd-0b3d-4370-98c2-23977427bbed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log loss(0, 0.1) ==> 0.10536051565782628\n",
            "+++++++++++++--------------------------++++++++++++++++++++++++\n",
            "log loss(1, 0.9) ==> 0.10536051565782628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_log_loss():\n",
        "  \"\"\"\n",
        "  Test cases for the log_loss function.\n",
        "  \"\"\"\n",
        "  import numpy as np\n",
        "  # Test case 1: Perfect prediction (y_true = 1, y_pred = 1)\n",
        "  y_true = 1\n",
        "  y_pred = 1\n",
        "  expected_loss = 0.0 # Log loss is 0 for perfect prediction\n",
        "  assert np.isclose(log_loss(y_true, y_pred), expected_loss), \"Test failed for perfect prediction (y_true=1, y_pred=1)\"\n",
        "  # Test case 2: Perfect prediction (y_true = 0, y_pred = 0)\n",
        "  y_true = 0\n",
        "  y_pred = 0\n",
        "  expected_loss = 0.0 # Log loss is 0 for perfect prediction\n",
        "  assert np.isclose(log_loss(y_true, y_pred), expected_loss), \"Test failed for perfect prediction (y_true=0, y_pred=0)\"\n",
        "  # Test case 3: Incorrect prediction (y_true = 1, y_pred = 0)\n",
        "  y_true = 1\n",
        "  y_pred = 0\n",
        "  try:\n",
        "    log_loss(y_true, y_pred) # This should raise an error due to log(0)\n",
        "  except ValueError:\n",
        "    pass # Test passed if ValueError is raised for log(0)\n",
        "  # Test case 4: Incorrect prediction (y_true = 0, y_pred = 1)\n",
        "  y_true = 0\n",
        "  y_pred = 1\n",
        "  try:\n",
        "    log_loss(y_true, y_pred) # This should raise an error due to log(0)\n",
        "  except ValueError:\n",
        "    pass # Test passed if ValueError is raised for log(0)\n",
        "  # Test case 5: Partially correct prediction\n",
        "  y_true = 1\n",
        "  y_pred = 0.8\n",
        "  expected_loss = -(1 * np.log(0.8)) - (0 * np.log(0.2)) # ~0.2231\n",
        "  assert np.isclose(log_loss(y_true, y_pred), expected_loss, atol=1e-6), \"Test failed for partially correct prediction (y_true=1, y_pred=0.8)\"\n",
        "  y_true = 0\n",
        "  y_pred = 0.2\n",
        "  expected_loss = -(0 * np.log(0.2)) - (1 * np.log(0.8)) # ~0.2231\n",
        "  assert np.isclose(log_loss(y_true, y_pred), expected_loss, atol=1e-6), \"Test failed for partially correct prediction (y_true=0, y_pred=0.2)\"\n",
        "  print(\"All tests passed!\")\n",
        "# Run the test case\n",
        "test_log_loss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrHP4ZjMriJg",
        "outputId": "44a84e5d-6b8c-4890-c3b3-ca9a9c752736"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task To Do:\n",
        "• Implement the Cost Function by completing the code or writing your own function.\n",
        "• Make sure you pass the test case."
      ],
      "metadata": {
        "id": "Fuh6mP4EtMd9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "iMPLEMENTATION OF COST FUNCTION"
      ],
      "metadata": {
        "id": "wEiqDYpcAzhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_function(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Computes log loss for inputs true value (0 or 1) and predicted value (between 0 and 1)\n",
        "    Args:\n",
        "    y_true (array_like, shape (n,)): array of true values (0 or 1)\n",
        "    y_pred (array_like, shape (n,)): array of predicted values (probability of y_pred being 1)\n",
        "    Returns:\n",
        "    cost (float): nonnegative cost corresponding to y_true and y_pred\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "\n",
        "    assert len(y_true) == len(y_pred), \"Length of true values and length of predicted values do not match\"\n",
        "\n",
        "    n = len(y_true)\n",
        "    loss_vec = -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "    cost = np.sum(loss_vec) / n\n",
        "\n",
        "    return cost\n"
      ],
      "metadata": {
        "id": "4mfrg_-YtLkM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the Cost Function:"
      ],
      "metadata": {
        "id": "DPeEagMRAtoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def test_cost_function():\n",
        "  # Test case 1: Simple example with known expected cost\n",
        "  y_true = np.array([1, 0, 1])\n",
        "  y_pred = np.array([0.9, 0.1, 0.8])\n",
        "  # Expected output: Manually calculate cost for these values\n",
        "  # log_loss(y_true, y_pred) for each example\n",
        "  expected_cost = (-(1 * np.log(0.9)) - (1 - 1) * np.log(1 - 0.9) +\n",
        "  -(0 * np.log(0.1)) - (1 - 0) * np.log(1 - 0.1) +\n",
        "  -(1 * np.log(0.8)) - (1 - 1) * np.log(1 - 0.8)) / 3\n",
        "\n",
        "  # Call the cost_function to get the result\n",
        "  result = cost_function(y_true, y_pred)\n",
        "  # Assert that the result is close to the expected cost with a tolerance of 1e-6\n",
        "  assert np.isclose(result, expected_cost, atol=1e-6), f\"Test failed: {result} != {expected_cost}\"\n",
        "  print(\"Test passed for simple case!\")\n",
        "  # Run the test case\n",
        "test_cost_function()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFSGXHFfAS9g",
        "outputId": "d49ea024-06b7-4405-8402-04e3291ee8d1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed for simple case!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task To Do:\n",
        "• Implement the vectorized cost function costfunction logreg Function by completing the\n",
        "code or writing your own function.\n",
        "• Make sure you pass the test case."
      ],
      "metadata": {
        "id": "KBhpxqqxA_h1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def costfunction_logreg(X, y, w, b):\n",
        "    \"\"\"\n",
        "    Computes the cost function, given data and model parameters.\n",
        "    \"\"\"\n",
        "    n, d = X.shape\n",
        "    assert len(y) == n, \"Number of feature observations and number of target observations do not match.\"\n",
        "    assert len(w) == d, \"Number of features and number of weight parameters do not match.\"\n",
        "\n",
        "    # Compute z using np.dot\n",
        "    z = np.dot(X, w) + b   # (n,d) · (d,) + scalar → (n,)\n",
        "\n",
        "    # Compute predictions using logistic function (sigmoid)\n",
        "    y_pred = 1 / (1 + np.exp(-z))\n",
        "\n",
        "    # Compute the cost using the cost function\n",
        "    cost = cost_function(y, y_pred)\n",
        "    return cost\n"
      ],
      "metadata": {
        "id": "ucsIokz1A4ka"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the function"
      ],
      "metadata": {
        "id": "Rh2DKNbqGU3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y, w, b = np.array([[10, 20], [-10, 10]]), np.array([1, 0]), np.array([0.5, 1.5]), 1\n",
        "print(f\"cost for logistic regression(X = {X}, y = {y}, w = {w}, b = {b}) = {costfunction_logreg(X, y, w, b)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRbLiB2qA8ZS",
        "outputId": "12a03275-3088-47c2-8dff-f8dce159493e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cost for logistic regression(X = [[ 10  20]\n",
            " [-10  10]], y = [1 0], w = [0.5 1.5], b = 1) = 5.500008350784906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task To Do:\n",
        "• Implement the compute gradient Function by completing the code or writing your own\n",
        "function.\n",
        "• Make sure you pass the test case."
      ],
      "metadata": {
        "id": "Oh_KyrZdJkF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient(X, y, w, b):\n",
        "    \"\"\"\n",
        "    Computes gradients of the cost function with respect to model parameters.\n",
        "    \"\"\"\n",
        "    n, d = X.shape\n",
        "    assert len(y) == n, f\"Expected y to have {n} elements, but got {len(y)}\"\n",
        "    assert len(w) == d, f\"Expected w to have {d} elements, but got {len(w)}\"\n",
        "\n",
        "    # Compute predictions using logistic function (sigmoid)\n",
        "    z = np.dot(X, w) + b\n",
        "    y_pred = 1 / (1 + np.exp(-z))\n",
        "\n",
        "    # Compute gradients\n",
        "    grad_w = -(1 / n) * np.dot(X.T, (y - y_pred))\n",
        "    grad_b = -(1 / n) * np.sum(y - y_pred)\n",
        "\n",
        "    return grad_w, grad_b\n"
      ],
      "metadata": {
        "id": "NuvK8eY0GbyB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple test case\n",
        "X = np.array([[10, 20], [-10, 10]]) # shape (2, 2)\n",
        "y = np.array([1, 0]) # shape (2,)\n",
        "w = np.array([0.5, 1.5]) # shape (2,)\n",
        "b = 1 # scalar\n",
        "# Assertion tests\n",
        "try:\n",
        "  grad_w, grad_b = compute_gradient(X, y, w, b)\n",
        "  print(\"Gradients computed successfully.\")\n",
        "  print(f\"grad_w: {grad_w}\")\n",
        "  print(f\"grad_b: {grad_b}\")\n",
        "except AssertionError as e:\n",
        "  print(f\"Assertion error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDFbLw0CK3zq",
        "outputId": "e2ac9a62-65b6-4057-fd59-df2e22cf5114"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients computed successfully.\n",
            "grad_w: [-4.99991649  4.99991649]\n",
            "grad_b: 0.4999916492890759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task To Do:\n",
        "• Implement the gradient descent Function by completing the code or writing your own\n",
        "function.\n",
        "• Make sure you pass the test case."
      ],
      "metadata": {
        "id": "3lZeOI2jLHMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y, w, b, alpha, n_iter, show_cost=False, show_params=True):\n",
        "    \"\"\"\n",
        "    Implements batch gradient descent to optimize logistic regression parameters.\n",
        "    \"\"\"\n",
        "    n, d = X.shape\n",
        "    assert len(y) == n, \"Number of observations in X and y do not match\"\n",
        "    assert len(w) == d, \"Number of features in X and w do not match\"\n",
        "\n",
        "    cost_history = []\n",
        "    params_history = []\n",
        "\n",
        "    for i in range(n_iter):\n",
        "        # Compute gradients\n",
        "        grad_w, grad_b = compute_gradient(X, y, w, b)\n",
        "\n",
        "        # Update weights and bias\n",
        "        w -= alpha * grad_w\n",
        "        b -= alpha * grad_b\n",
        "\n",
        "        # Compute cost\n",
        "        y_pred = 1 / (1 + np.exp(-(np.dot(X, w) + b)))\n",
        "        cost = cost_function(y, y_pred)\n",
        "\n",
        "        # Store cost and parameters\n",
        "        cost_history.append(cost)\n",
        "        params_history.append((w.copy(), b))\n",
        "\n",
        "        # Optionally print cost and parameters\n",
        "        if show_cost and (i % 100 == 0 or i == n_iter - 1):\n",
        "            print(f\"Iteration {i}: Cost = {cost:.6f}\")\n",
        "\n",
        "        if show_params and (i % 100 == 0 or i == n_iter - 1):\n",
        "            print(f\"Iteration {i}: w = {w}, b = {b:.6f}\")\n",
        "\n",
        "    return w, b, cost_history, params_history\n"
      ],
      "metadata": {
        "id": "SdOqXKA7LAPJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the gradient_descent function with sample data\n",
        "X = np.array([[0.1, 0.2], [-0.1, 0.1]]) # Shape (2, 2)\n",
        "y = np.array([1, 0]) # Shape (2,)\n",
        "w = np.zeros(X.shape[1]) # Shape (2,) - same as number of features\n",
        "b = 0.0 # Scalar\n",
        "alpha = 0.1 # Learning rate\n",
        "n_iter = 100000 # Number of iterations\n",
        "# Perform gradient descent\n",
        "w_out, b_out, cost_history, params_history = gradient_descent(X, y, w, b, alpha, n_iter, show_cost=True,\n",
        "show_params=False)\n",
        "# Print final parameters and cost\n",
        "print(\"\\nFinal parameters:\")\n",
        "print(f\"w: {w_out}, b: {b_out}\")\n",
        "print(f\"Final cost: {cost_history[-1]:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wPNwCsbSXTn",
        "outputId": "7187b48f-9bab-4a29-919e-b48280e9ec04"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Cost = 0.692835\n",
            "Iteration 100: Cost = 0.662662\n",
            "Iteration 200: Cost = 0.634332\n",
            "Iteration 300: Cost = 0.607704\n",
            "Iteration 400: Cost = 0.582671\n",
            "Iteration 500: Cost = 0.559128\n",
            "Iteration 600: Cost = 0.536977\n",
            "Iteration 700: Cost = 0.516126\n",
            "Iteration 800: Cost = 0.496487\n",
            "Iteration 900: Cost = 0.477978\n",
            "Iteration 1000: Cost = 0.460524\n",
            "Iteration 1100: Cost = 0.444052\n",
            "Iteration 1200: Cost = 0.428497\n",
            "Iteration 1300: Cost = 0.413797\n",
            "Iteration 1400: Cost = 0.399895\n",
            "Iteration 1500: Cost = 0.386736\n",
            "Iteration 1600: Cost = 0.374272\n",
            "Iteration 1700: Cost = 0.362457\n",
            "Iteration 1800: Cost = 0.351248\n",
            "Iteration 1900: Cost = 0.340607\n",
            "Iteration 2000: Cost = 0.330495\n",
            "Iteration 2100: Cost = 0.320880\n",
            "Iteration 2200: Cost = 0.311730\n",
            "Iteration 2300: Cost = 0.303016\n",
            "Iteration 2400: Cost = 0.294710\n",
            "Iteration 2500: Cost = 0.286789\n",
            "Iteration 2600: Cost = 0.279228\n",
            "Iteration 2700: Cost = 0.272007\n",
            "Iteration 2800: Cost = 0.265104\n",
            "Iteration 2900: Cost = 0.258502\n",
            "Iteration 3000: Cost = 0.252182\n",
            "Iteration 3100: Cost = 0.246129\n",
            "Iteration 3200: Cost = 0.240328\n",
            "Iteration 3300: Cost = 0.234764\n",
            "Iteration 3400: Cost = 0.229425\n",
            "Iteration 3500: Cost = 0.224299\n",
            "Iteration 3600: Cost = 0.219373\n",
            "Iteration 3700: Cost = 0.214637\n",
            "Iteration 3800: Cost = 0.210081\n",
            "Iteration 3900: Cost = 0.205697\n",
            "Iteration 4000: Cost = 0.201474\n",
            "Iteration 4100: Cost = 0.197406\n",
            "Iteration 4200: Cost = 0.193484\n",
            "Iteration 4300: Cost = 0.189700\n",
            "Iteration 4400: Cost = 0.186049\n",
            "Iteration 4500: Cost = 0.182524\n",
            "Iteration 4600: Cost = 0.179119\n",
            "Iteration 4700: Cost = 0.175828\n",
            "Iteration 4800: Cost = 0.172646\n",
            "Iteration 4900: Cost = 0.169568\n",
            "Iteration 5000: Cost = 0.166589\n",
            "Iteration 5100: Cost = 0.163705\n",
            "Iteration 5200: Cost = 0.160912\n",
            "Iteration 5300: Cost = 0.158205\n",
            "Iteration 5400: Cost = 0.155581\n",
            "Iteration 5500: Cost = 0.153036\n",
            "Iteration 5600: Cost = 0.150568\n",
            "Iteration 5700: Cost = 0.148172\n",
            "Iteration 5800: Cost = 0.145846\n",
            "Iteration 5900: Cost = 0.143586\n",
            "Iteration 6000: Cost = 0.141392\n",
            "Iteration 6100: Cost = 0.139258\n",
            "Iteration 6200: Cost = 0.137184\n",
            "Iteration 6300: Cost = 0.135167\n",
            "Iteration 6400: Cost = 0.133205\n",
            "Iteration 6500: Cost = 0.131295\n",
            "Iteration 6600: Cost = 0.129436\n",
            "Iteration 6700: Cost = 0.127625\n",
            "Iteration 6800: Cost = 0.125862\n",
            "Iteration 6900: Cost = 0.124143\n",
            "Iteration 7000: Cost = 0.122469\n",
            "Iteration 7100: Cost = 0.120836\n",
            "Iteration 7200: Cost = 0.119243\n",
            "Iteration 7300: Cost = 0.117690\n",
            "Iteration 7400: Cost = 0.116175\n",
            "Iteration 7500: Cost = 0.114695\n",
            "Iteration 7600: Cost = 0.113251\n",
            "Iteration 7700: Cost = 0.111841\n",
            "Iteration 7800: Cost = 0.110464\n",
            "Iteration 7900: Cost = 0.109118\n",
            "Iteration 8000: Cost = 0.107804\n",
            "Iteration 8100: Cost = 0.106518\n",
            "Iteration 8200: Cost = 0.105262\n",
            "Iteration 8300: Cost = 0.104033\n",
            "Iteration 8400: Cost = 0.102832\n",
            "Iteration 8500: Cost = 0.101656\n",
            "Iteration 8600: Cost = 0.100506\n",
            "Iteration 8700: Cost = 0.099380\n",
            "Iteration 8800: Cost = 0.098278\n",
            "Iteration 8900: Cost = 0.097199\n",
            "Iteration 9000: Cost = 0.096142\n",
            "Iteration 9100: Cost = 0.095107\n",
            "Iteration 9200: Cost = 0.094093\n",
            "Iteration 9300: Cost = 0.093100\n",
            "Iteration 9400: Cost = 0.092126\n",
            "Iteration 9500: Cost = 0.091172\n",
            "Iteration 9600: Cost = 0.090236\n",
            "Iteration 9700: Cost = 0.089318\n",
            "Iteration 9800: Cost = 0.088418\n",
            "Iteration 9900: Cost = 0.087536\n",
            "Iteration 10000: Cost = 0.086670\n",
            "Iteration 10100: Cost = 0.085820\n",
            "Iteration 10200: Cost = 0.084986\n",
            "Iteration 10300: Cost = 0.084168\n",
            "Iteration 10400: Cost = 0.083364\n",
            "Iteration 10500: Cost = 0.082575\n",
            "Iteration 10600: Cost = 0.081800\n",
            "Iteration 10700: Cost = 0.081039\n",
            "Iteration 10800: Cost = 0.080292\n",
            "Iteration 10900: Cost = 0.079558\n",
            "Iteration 11000: Cost = 0.078836\n",
            "Iteration 11100: Cost = 0.078127\n",
            "Iteration 11200: Cost = 0.077430\n",
            "Iteration 11300: Cost = 0.076745\n",
            "Iteration 11400: Cost = 0.076072\n",
            "Iteration 11500: Cost = 0.075409\n",
            "Iteration 11600: Cost = 0.074758\n",
            "Iteration 11700: Cost = 0.074118\n",
            "Iteration 11800: Cost = 0.073488\n",
            "Iteration 11900: Cost = 0.072868\n",
            "Iteration 12000: Cost = 0.072259\n",
            "Iteration 12100: Cost = 0.071659\n",
            "Iteration 12200: Cost = 0.071068\n",
            "Iteration 12300: Cost = 0.070487\n",
            "Iteration 12400: Cost = 0.069915\n",
            "Iteration 12500: Cost = 0.069352\n",
            "Iteration 12600: Cost = 0.068798\n",
            "Iteration 12700: Cost = 0.068252\n",
            "Iteration 12800: Cost = 0.067714\n",
            "Iteration 12900: Cost = 0.067185\n",
            "Iteration 13000: Cost = 0.066663\n",
            "Iteration 13100: Cost = 0.066149\n",
            "Iteration 13200: Cost = 0.065643\n",
            "Iteration 13300: Cost = 0.065145\n",
            "Iteration 13400: Cost = 0.064653\n",
            "Iteration 13500: Cost = 0.064169\n",
            "Iteration 13600: Cost = 0.063692\n",
            "Iteration 13700: Cost = 0.063221\n",
            "Iteration 13800: Cost = 0.062757\n",
            "Iteration 13900: Cost = 0.062300\n",
            "Iteration 14000: Cost = 0.061849\n",
            "Iteration 14100: Cost = 0.061405\n",
            "Iteration 14200: Cost = 0.060966\n",
            "Iteration 14300: Cost = 0.060534\n",
            "Iteration 14400: Cost = 0.060108\n",
            "Iteration 14500: Cost = 0.059687\n",
            "Iteration 14600: Cost = 0.059272\n",
            "Iteration 14700: Cost = 0.058862\n",
            "Iteration 14800: Cost = 0.058459\n",
            "Iteration 14900: Cost = 0.058060\n",
            "Iteration 15000: Cost = 0.057667\n",
            "Iteration 15100: Cost = 0.057278\n",
            "Iteration 15200: Cost = 0.056895\n",
            "Iteration 15300: Cost = 0.056517\n",
            "Iteration 15400: Cost = 0.056144\n",
            "Iteration 15500: Cost = 0.055775\n",
            "Iteration 15600: Cost = 0.055411\n",
            "Iteration 15700: Cost = 0.055052\n",
            "Iteration 15800: Cost = 0.054697\n",
            "Iteration 15900: Cost = 0.054346\n",
            "Iteration 16000: Cost = 0.054000\n",
            "Iteration 16100: Cost = 0.053659\n",
            "Iteration 16200: Cost = 0.053321\n",
            "Iteration 16300: Cost = 0.052987\n",
            "Iteration 16400: Cost = 0.052658\n",
            "Iteration 16500: Cost = 0.052333\n",
            "Iteration 16600: Cost = 0.052011\n",
            "Iteration 16700: Cost = 0.051693\n",
            "Iteration 16800: Cost = 0.051379\n",
            "Iteration 16900: Cost = 0.051069\n",
            "Iteration 17000: Cost = 0.050762\n",
            "Iteration 17100: Cost = 0.050459\n",
            "Iteration 17200: Cost = 0.050159\n",
            "Iteration 17300: Cost = 0.049863\n",
            "Iteration 17400: Cost = 0.049571\n",
            "Iteration 17500: Cost = 0.049281\n",
            "Iteration 17600: Cost = 0.048995\n",
            "Iteration 17700: Cost = 0.048712\n",
            "Iteration 17800: Cost = 0.048432\n",
            "Iteration 17900: Cost = 0.048156\n",
            "Iteration 18000: Cost = 0.047882\n",
            "Iteration 18100: Cost = 0.047612\n",
            "Iteration 18200: Cost = 0.047344\n",
            "Iteration 18300: Cost = 0.047079\n",
            "Iteration 18400: Cost = 0.046818\n",
            "Iteration 18500: Cost = 0.046559\n",
            "Iteration 18600: Cost = 0.046302\n",
            "Iteration 18700: Cost = 0.046049\n",
            "Iteration 18800: Cost = 0.045798\n",
            "Iteration 18900: Cost = 0.045550\n",
            "Iteration 19000: Cost = 0.045305\n",
            "Iteration 19100: Cost = 0.045062\n",
            "Iteration 19200: Cost = 0.044822\n",
            "Iteration 19300: Cost = 0.044584\n",
            "Iteration 19400: Cost = 0.044348\n",
            "Iteration 19500: Cost = 0.044115\n",
            "Iteration 19600: Cost = 0.043885\n",
            "Iteration 19700: Cost = 0.043656\n",
            "Iteration 19800: Cost = 0.043430\n",
            "Iteration 19900: Cost = 0.043207\n",
            "Iteration 20000: Cost = 0.042985\n",
            "Iteration 20100: Cost = 0.042766\n",
            "Iteration 20200: Cost = 0.042549\n",
            "Iteration 20300: Cost = 0.042334\n",
            "Iteration 20400: Cost = 0.042121\n",
            "Iteration 20500: Cost = 0.041911\n",
            "Iteration 20600: Cost = 0.041702\n",
            "Iteration 20700: Cost = 0.041495\n",
            "Iteration 20800: Cost = 0.041291\n",
            "Iteration 20900: Cost = 0.041088\n",
            "Iteration 21000: Cost = 0.040888\n",
            "Iteration 21100: Cost = 0.040689\n",
            "Iteration 21200: Cost = 0.040492\n",
            "Iteration 21300: Cost = 0.040297\n",
            "Iteration 21400: Cost = 0.040104\n",
            "Iteration 21500: Cost = 0.039912\n",
            "Iteration 21600: Cost = 0.039722\n",
            "Iteration 21700: Cost = 0.039535\n",
            "Iteration 21800: Cost = 0.039348\n",
            "Iteration 21900: Cost = 0.039164\n",
            "Iteration 22000: Cost = 0.038981\n",
            "Iteration 22100: Cost = 0.038800\n",
            "Iteration 22200: Cost = 0.038621\n",
            "Iteration 22300: Cost = 0.038443\n",
            "Iteration 22400: Cost = 0.038267\n",
            "Iteration 22500: Cost = 0.038092\n",
            "Iteration 22600: Cost = 0.037919\n",
            "Iteration 22700: Cost = 0.037748\n",
            "Iteration 22800: Cost = 0.037577\n",
            "Iteration 22900: Cost = 0.037409\n",
            "Iteration 23000: Cost = 0.037242\n",
            "Iteration 23100: Cost = 0.037076\n",
            "Iteration 23200: Cost = 0.036912\n",
            "Iteration 23300: Cost = 0.036749\n",
            "Iteration 23400: Cost = 0.036588\n",
            "Iteration 23500: Cost = 0.036428\n",
            "Iteration 23600: Cost = 0.036270\n",
            "Iteration 23700: Cost = 0.036112\n",
            "Iteration 23800: Cost = 0.035956\n",
            "Iteration 23900: Cost = 0.035802\n",
            "Iteration 24000: Cost = 0.035649\n",
            "Iteration 24100: Cost = 0.035497\n",
            "Iteration 24200: Cost = 0.035346\n",
            "Iteration 24300: Cost = 0.035196\n",
            "Iteration 24400: Cost = 0.035048\n",
            "Iteration 24500: Cost = 0.034901\n",
            "Iteration 24600: Cost = 0.034755\n",
            "Iteration 24700: Cost = 0.034611\n",
            "Iteration 24800: Cost = 0.034467\n",
            "Iteration 24900: Cost = 0.034325\n",
            "Iteration 25000: Cost = 0.034184\n",
            "Iteration 25100: Cost = 0.034044\n",
            "Iteration 25200: Cost = 0.033905\n",
            "Iteration 25300: Cost = 0.033767\n",
            "Iteration 25400: Cost = 0.033631\n",
            "Iteration 25500: Cost = 0.033495\n",
            "Iteration 25600: Cost = 0.033361\n",
            "Iteration 25700: Cost = 0.033227\n",
            "Iteration 25800: Cost = 0.033095\n",
            "Iteration 25900: Cost = 0.032963\n",
            "Iteration 26000: Cost = 0.032833\n",
            "Iteration 26100: Cost = 0.032704\n",
            "Iteration 26200: Cost = 0.032575\n",
            "Iteration 26300: Cost = 0.032448\n",
            "Iteration 26400: Cost = 0.032322\n",
            "Iteration 26500: Cost = 0.032196\n",
            "Iteration 26600: Cost = 0.032072\n",
            "Iteration 26700: Cost = 0.031948\n",
            "Iteration 26800: Cost = 0.031826\n",
            "Iteration 26900: Cost = 0.031704\n",
            "Iteration 27000: Cost = 0.031583\n",
            "Iteration 27100: Cost = 0.031463\n",
            "Iteration 27200: Cost = 0.031344\n",
            "Iteration 27300: Cost = 0.031226\n",
            "Iteration 27400: Cost = 0.031109\n",
            "Iteration 27500: Cost = 0.030993\n",
            "Iteration 27600: Cost = 0.030877\n",
            "Iteration 27700: Cost = 0.030763\n",
            "Iteration 27800: Cost = 0.030649\n",
            "Iteration 27900: Cost = 0.030536\n",
            "Iteration 28000: Cost = 0.030424\n",
            "Iteration 28100: Cost = 0.030312\n",
            "Iteration 28200: Cost = 0.030202\n",
            "Iteration 28300: Cost = 0.030092\n",
            "Iteration 28400: Cost = 0.029983\n",
            "Iteration 28500: Cost = 0.029875\n",
            "Iteration 28600: Cost = 0.029768\n",
            "Iteration 28700: Cost = 0.029661\n",
            "Iteration 28800: Cost = 0.029555\n",
            "Iteration 28900: Cost = 0.029450\n",
            "Iteration 29000: Cost = 0.029345\n",
            "Iteration 29100: Cost = 0.029242\n",
            "Iteration 29200: Cost = 0.029139\n",
            "Iteration 29300: Cost = 0.029036\n",
            "Iteration 29400: Cost = 0.028935\n",
            "Iteration 29500: Cost = 0.028834\n",
            "Iteration 29600: Cost = 0.028734\n",
            "Iteration 29700: Cost = 0.028634\n",
            "Iteration 29800: Cost = 0.028535\n",
            "Iteration 29900: Cost = 0.028437\n",
            "Iteration 30000: Cost = 0.028340\n",
            "Iteration 30100: Cost = 0.028243\n",
            "Iteration 30200: Cost = 0.028147\n",
            "Iteration 30300: Cost = 0.028051\n",
            "Iteration 30400: Cost = 0.027956\n",
            "Iteration 30500: Cost = 0.027862\n",
            "Iteration 30600: Cost = 0.027768\n",
            "Iteration 30700: Cost = 0.027675\n",
            "Iteration 30800: Cost = 0.027583\n",
            "Iteration 30900: Cost = 0.027491\n",
            "Iteration 31000: Cost = 0.027400\n",
            "Iteration 31100: Cost = 0.027309\n",
            "Iteration 31200: Cost = 0.027219\n",
            "Iteration 31300: Cost = 0.027130\n",
            "Iteration 31400: Cost = 0.027041\n",
            "Iteration 31500: Cost = 0.026953\n",
            "Iteration 31600: Cost = 0.026865\n",
            "Iteration 31700: Cost = 0.026778\n",
            "Iteration 31800: Cost = 0.026691\n",
            "Iteration 31900: Cost = 0.026605\n",
            "Iteration 32000: Cost = 0.026519\n",
            "Iteration 32100: Cost = 0.026435\n",
            "Iteration 32200: Cost = 0.026350\n",
            "Iteration 32300: Cost = 0.026266\n",
            "Iteration 32400: Cost = 0.026183\n",
            "Iteration 32500: Cost = 0.026100\n",
            "Iteration 32600: Cost = 0.026018\n",
            "Iteration 32700: Cost = 0.025936\n",
            "Iteration 32800: Cost = 0.025854\n",
            "Iteration 32900: Cost = 0.025774\n",
            "Iteration 33000: Cost = 0.025693\n",
            "Iteration 33100: Cost = 0.025613\n",
            "Iteration 33200: Cost = 0.025534\n",
            "Iteration 33300: Cost = 0.025455\n",
            "Iteration 33400: Cost = 0.025377\n",
            "Iteration 33500: Cost = 0.025299\n",
            "Iteration 33600: Cost = 0.025222\n",
            "Iteration 33700: Cost = 0.025145\n",
            "Iteration 33800: Cost = 0.025068\n",
            "Iteration 33900: Cost = 0.024992\n",
            "Iteration 34000: Cost = 0.024916\n",
            "Iteration 34100: Cost = 0.024841\n",
            "Iteration 34200: Cost = 0.024767\n",
            "Iteration 34300: Cost = 0.024692\n",
            "Iteration 34400: Cost = 0.024619\n",
            "Iteration 34500: Cost = 0.024545\n",
            "Iteration 34600: Cost = 0.024472\n",
            "Iteration 34700: Cost = 0.024400\n",
            "Iteration 34800: Cost = 0.024328\n",
            "Iteration 34900: Cost = 0.024256\n",
            "Iteration 35000: Cost = 0.024185\n",
            "Iteration 35100: Cost = 0.024114\n",
            "Iteration 35200: Cost = 0.024043\n",
            "Iteration 35300: Cost = 0.023973\n",
            "Iteration 35400: Cost = 0.023904\n",
            "Iteration 35500: Cost = 0.023834\n",
            "Iteration 35600: Cost = 0.023766\n",
            "Iteration 35700: Cost = 0.023697\n",
            "Iteration 35800: Cost = 0.023629\n",
            "Iteration 35900: Cost = 0.023561\n",
            "Iteration 36000: Cost = 0.023494\n",
            "Iteration 36100: Cost = 0.023427\n",
            "Iteration 36200: Cost = 0.023361\n",
            "Iteration 36300: Cost = 0.023295\n",
            "Iteration 36400: Cost = 0.023229\n",
            "Iteration 36500: Cost = 0.023163\n",
            "Iteration 36600: Cost = 0.023098\n",
            "Iteration 36700: Cost = 0.023034\n",
            "Iteration 36800: Cost = 0.022969\n",
            "Iteration 36900: Cost = 0.022905\n",
            "Iteration 37000: Cost = 0.022842\n",
            "Iteration 37100: Cost = 0.022778\n",
            "Iteration 37200: Cost = 0.022715\n",
            "Iteration 37300: Cost = 0.022653\n",
            "Iteration 37400: Cost = 0.022590\n",
            "Iteration 37500: Cost = 0.022529\n",
            "Iteration 37600: Cost = 0.022467\n",
            "Iteration 37700: Cost = 0.022406\n",
            "Iteration 37800: Cost = 0.022345\n",
            "Iteration 37900: Cost = 0.022284\n",
            "Iteration 38000: Cost = 0.022224\n",
            "Iteration 38100: Cost = 0.022164\n",
            "Iteration 38200: Cost = 0.022104\n",
            "Iteration 38300: Cost = 0.022045\n",
            "Iteration 38400: Cost = 0.021986\n",
            "Iteration 38500: Cost = 0.021927\n",
            "Iteration 38600: Cost = 0.021869\n",
            "Iteration 38700: Cost = 0.021811\n",
            "Iteration 38800: Cost = 0.021753\n",
            "Iteration 38900: Cost = 0.021696\n",
            "Iteration 39000: Cost = 0.021638\n",
            "Iteration 39100: Cost = 0.021581\n",
            "Iteration 39200: Cost = 0.021525\n",
            "Iteration 39300: Cost = 0.021469\n",
            "Iteration 39400: Cost = 0.021413\n",
            "Iteration 39500: Cost = 0.021357\n",
            "Iteration 39600: Cost = 0.021301\n",
            "Iteration 39700: Cost = 0.021246\n",
            "Iteration 39800: Cost = 0.021191\n",
            "Iteration 39900: Cost = 0.021137\n",
            "Iteration 40000: Cost = 0.021083\n",
            "Iteration 40100: Cost = 0.021029\n",
            "Iteration 40200: Cost = 0.020975\n",
            "Iteration 40300: Cost = 0.020921\n",
            "Iteration 40400: Cost = 0.020868\n",
            "Iteration 40500: Cost = 0.020815\n",
            "Iteration 40600: Cost = 0.020762\n",
            "Iteration 40700: Cost = 0.020710\n",
            "Iteration 40800: Cost = 0.020658\n",
            "Iteration 40900: Cost = 0.020606\n",
            "Iteration 41000: Cost = 0.020554\n",
            "Iteration 41100: Cost = 0.020503\n",
            "Iteration 41200: Cost = 0.020452\n",
            "Iteration 41300: Cost = 0.020401\n",
            "Iteration 41400: Cost = 0.020350\n",
            "Iteration 41500: Cost = 0.020300\n",
            "Iteration 41600: Cost = 0.020250\n",
            "Iteration 41700: Cost = 0.020200\n",
            "Iteration 41800: Cost = 0.020150\n",
            "Iteration 41900: Cost = 0.020101\n",
            "Iteration 42000: Cost = 0.020052\n",
            "Iteration 42100: Cost = 0.020003\n",
            "Iteration 42200: Cost = 0.019954\n",
            "Iteration 42300: Cost = 0.019906\n",
            "Iteration 42400: Cost = 0.019857\n",
            "Iteration 42500: Cost = 0.019809\n",
            "Iteration 42600: Cost = 0.019762\n",
            "Iteration 42700: Cost = 0.019714\n",
            "Iteration 42800: Cost = 0.019667\n",
            "Iteration 42900: Cost = 0.019620\n",
            "Iteration 43000: Cost = 0.019573\n",
            "Iteration 43100: Cost = 0.019526\n",
            "Iteration 43200: Cost = 0.019480\n",
            "Iteration 43300: Cost = 0.019434\n",
            "Iteration 43400: Cost = 0.019388\n",
            "Iteration 43500: Cost = 0.019342\n",
            "Iteration 43600: Cost = 0.019296\n",
            "Iteration 43700: Cost = 0.019251\n",
            "Iteration 43800: Cost = 0.019206\n",
            "Iteration 43900: Cost = 0.019161\n",
            "Iteration 44000: Cost = 0.019116\n",
            "Iteration 44100: Cost = 0.019072\n",
            "Iteration 44200: Cost = 0.019027\n",
            "Iteration 44300: Cost = 0.018983\n",
            "Iteration 44400: Cost = 0.018939\n",
            "Iteration 44500: Cost = 0.018896\n",
            "Iteration 44600: Cost = 0.018852\n",
            "Iteration 44700: Cost = 0.018809\n",
            "Iteration 44800: Cost = 0.018766\n",
            "Iteration 44900: Cost = 0.018723\n",
            "Iteration 45000: Cost = 0.018680\n",
            "Iteration 45100: Cost = 0.018638\n",
            "Iteration 45200: Cost = 0.018595\n",
            "Iteration 45300: Cost = 0.018553\n",
            "Iteration 45400: Cost = 0.018511\n",
            "Iteration 45500: Cost = 0.018469\n",
            "Iteration 45600: Cost = 0.018428\n",
            "Iteration 45700: Cost = 0.018386\n",
            "Iteration 45800: Cost = 0.018345\n",
            "Iteration 45900: Cost = 0.018304\n",
            "Iteration 46000: Cost = 0.018263\n",
            "Iteration 46100: Cost = 0.018223\n",
            "Iteration 46200: Cost = 0.018182\n",
            "Iteration 46300: Cost = 0.018142\n",
            "Iteration 46400: Cost = 0.018102\n",
            "Iteration 46500: Cost = 0.018062\n",
            "Iteration 46600: Cost = 0.018022\n",
            "Iteration 46700: Cost = 0.017982\n",
            "Iteration 46800: Cost = 0.017943\n",
            "Iteration 46900: Cost = 0.017904\n",
            "Iteration 47000: Cost = 0.017864\n",
            "Iteration 47100: Cost = 0.017826\n",
            "Iteration 47200: Cost = 0.017787\n",
            "Iteration 47300: Cost = 0.017748\n",
            "Iteration 47400: Cost = 0.017710\n",
            "Iteration 47500: Cost = 0.017671\n",
            "Iteration 47600: Cost = 0.017633\n",
            "Iteration 47700: Cost = 0.017595\n",
            "Iteration 47800: Cost = 0.017558\n",
            "Iteration 47900: Cost = 0.017520\n",
            "Iteration 48000: Cost = 0.017483\n",
            "Iteration 48100: Cost = 0.017445\n",
            "Iteration 48200: Cost = 0.017408\n",
            "Iteration 48300: Cost = 0.017371\n",
            "Iteration 48400: Cost = 0.017334\n",
            "Iteration 48500: Cost = 0.017298\n",
            "Iteration 48600: Cost = 0.017261\n",
            "Iteration 48700: Cost = 0.017225\n",
            "Iteration 48800: Cost = 0.017189\n",
            "Iteration 48900: Cost = 0.017152\n",
            "Iteration 49000: Cost = 0.017117\n",
            "Iteration 49100: Cost = 0.017081\n",
            "Iteration 49200: Cost = 0.017045\n",
            "Iteration 49300: Cost = 0.017010\n",
            "Iteration 49400: Cost = 0.016974\n",
            "Iteration 49500: Cost = 0.016939\n",
            "Iteration 49600: Cost = 0.016904\n",
            "Iteration 49700: Cost = 0.016869\n",
            "Iteration 49800: Cost = 0.016834\n",
            "Iteration 49900: Cost = 0.016800\n",
            "Iteration 50000: Cost = 0.016765\n",
            "Iteration 50100: Cost = 0.016731\n",
            "Iteration 50200: Cost = 0.016697\n",
            "Iteration 50300: Cost = 0.016663\n",
            "Iteration 50400: Cost = 0.016629\n",
            "Iteration 50500: Cost = 0.016595\n",
            "Iteration 50600: Cost = 0.016561\n",
            "Iteration 50700: Cost = 0.016528\n",
            "Iteration 50800: Cost = 0.016495\n",
            "Iteration 50900: Cost = 0.016461\n",
            "Iteration 51000: Cost = 0.016428\n",
            "Iteration 51100: Cost = 0.016395\n",
            "Iteration 51200: Cost = 0.016362\n",
            "Iteration 51300: Cost = 0.016330\n",
            "Iteration 51400: Cost = 0.016297\n",
            "Iteration 51500: Cost = 0.016265\n",
            "Iteration 51600: Cost = 0.016232\n",
            "Iteration 51700: Cost = 0.016200\n",
            "Iteration 51800: Cost = 0.016168\n",
            "Iteration 51900: Cost = 0.016136\n",
            "Iteration 52000: Cost = 0.016104\n",
            "Iteration 52100: Cost = 0.016073\n",
            "Iteration 52200: Cost = 0.016041\n",
            "Iteration 52300: Cost = 0.016010\n",
            "Iteration 52400: Cost = 0.015978\n",
            "Iteration 52500: Cost = 0.015947\n",
            "Iteration 52600: Cost = 0.015916\n",
            "Iteration 52700: Cost = 0.015885\n",
            "Iteration 52800: Cost = 0.015854\n",
            "Iteration 52900: Cost = 0.015823\n",
            "Iteration 53000: Cost = 0.015793\n",
            "Iteration 53100: Cost = 0.015762\n",
            "Iteration 53200: Cost = 0.015732\n",
            "Iteration 53300: Cost = 0.015702\n",
            "Iteration 53400: Cost = 0.015672\n",
            "Iteration 53500: Cost = 0.015641\n",
            "Iteration 53600: Cost = 0.015612\n",
            "Iteration 53700: Cost = 0.015582\n",
            "Iteration 53800: Cost = 0.015552\n",
            "Iteration 53900: Cost = 0.015522\n",
            "Iteration 54000: Cost = 0.015493\n",
            "Iteration 54100: Cost = 0.015464\n",
            "Iteration 54200: Cost = 0.015434\n",
            "Iteration 54300: Cost = 0.015405\n",
            "Iteration 54400: Cost = 0.015376\n",
            "Iteration 54500: Cost = 0.015347\n",
            "Iteration 54600: Cost = 0.015318\n",
            "Iteration 54700: Cost = 0.015290\n",
            "Iteration 54800: Cost = 0.015261\n",
            "Iteration 54900: Cost = 0.015233\n",
            "Iteration 55000: Cost = 0.015204\n",
            "Iteration 55100: Cost = 0.015176\n",
            "Iteration 55200: Cost = 0.015148\n",
            "Iteration 55300: Cost = 0.015120\n",
            "Iteration 55400: Cost = 0.015092\n",
            "Iteration 55500: Cost = 0.015064\n",
            "Iteration 55600: Cost = 0.015036\n",
            "Iteration 55700: Cost = 0.015008\n",
            "Iteration 55800: Cost = 0.014981\n",
            "Iteration 55900: Cost = 0.014953\n",
            "Iteration 56000: Cost = 0.014926\n",
            "Iteration 56100: Cost = 0.014899\n",
            "Iteration 56200: Cost = 0.014872\n",
            "Iteration 56300: Cost = 0.014845\n",
            "Iteration 56400: Cost = 0.014818\n",
            "Iteration 56500: Cost = 0.014791\n",
            "Iteration 56600: Cost = 0.014764\n",
            "Iteration 56700: Cost = 0.014737\n",
            "Iteration 56800: Cost = 0.014711\n",
            "Iteration 56900: Cost = 0.014684\n",
            "Iteration 57000: Cost = 0.014658\n",
            "Iteration 57100: Cost = 0.014632\n",
            "Iteration 57200: Cost = 0.014605\n",
            "Iteration 57300: Cost = 0.014579\n",
            "Iteration 57400: Cost = 0.014553\n",
            "Iteration 57500: Cost = 0.014527\n",
            "Iteration 57600: Cost = 0.014501\n",
            "Iteration 57700: Cost = 0.014476\n",
            "Iteration 57800: Cost = 0.014450\n",
            "Iteration 57900: Cost = 0.014424\n",
            "Iteration 58000: Cost = 0.014399\n",
            "Iteration 58100: Cost = 0.014374\n",
            "Iteration 58200: Cost = 0.014348\n",
            "Iteration 58300: Cost = 0.014323\n",
            "Iteration 58400: Cost = 0.014298\n",
            "Iteration 58500: Cost = 0.014273\n",
            "Iteration 58600: Cost = 0.014248\n",
            "Iteration 58700: Cost = 0.014223\n",
            "Iteration 58800: Cost = 0.014198\n",
            "Iteration 58900: Cost = 0.014174\n",
            "Iteration 59000: Cost = 0.014149\n",
            "Iteration 59100: Cost = 0.014124\n",
            "Iteration 59200: Cost = 0.014100\n",
            "Iteration 59300: Cost = 0.014076\n",
            "Iteration 59400: Cost = 0.014051\n",
            "Iteration 59500: Cost = 0.014027\n",
            "Iteration 59600: Cost = 0.014003\n",
            "Iteration 59700: Cost = 0.013979\n",
            "Iteration 59800: Cost = 0.013955\n",
            "Iteration 59900: Cost = 0.013931\n",
            "Iteration 60000: Cost = 0.013907\n",
            "Iteration 60100: Cost = 0.013884\n",
            "Iteration 60200: Cost = 0.013860\n",
            "Iteration 60300: Cost = 0.013837\n",
            "Iteration 60400: Cost = 0.013813\n",
            "Iteration 60500: Cost = 0.013790\n",
            "Iteration 60600: Cost = 0.013766\n",
            "Iteration 60700: Cost = 0.013743\n",
            "Iteration 60800: Cost = 0.013720\n",
            "Iteration 60900: Cost = 0.013697\n",
            "Iteration 61000: Cost = 0.013674\n",
            "Iteration 61100: Cost = 0.013651\n",
            "Iteration 61200: Cost = 0.013628\n",
            "Iteration 61300: Cost = 0.013606\n",
            "Iteration 61400: Cost = 0.013583\n",
            "Iteration 61500: Cost = 0.013560\n",
            "Iteration 61600: Cost = 0.013538\n",
            "Iteration 61700: Cost = 0.013515\n",
            "Iteration 61800: Cost = 0.013493\n",
            "Iteration 61900: Cost = 0.013471\n",
            "Iteration 62000: Cost = 0.013448\n",
            "Iteration 62100: Cost = 0.013426\n",
            "Iteration 62200: Cost = 0.013404\n",
            "Iteration 62300: Cost = 0.013382\n",
            "Iteration 62400: Cost = 0.013360\n",
            "Iteration 62500: Cost = 0.013338\n",
            "Iteration 62600: Cost = 0.013316\n",
            "Iteration 62700: Cost = 0.013295\n",
            "Iteration 62800: Cost = 0.013273\n",
            "Iteration 62900: Cost = 0.013251\n",
            "Iteration 63000: Cost = 0.013230\n",
            "Iteration 63100: Cost = 0.013208\n",
            "Iteration 63200: Cost = 0.013187\n",
            "Iteration 63300: Cost = 0.013166\n",
            "Iteration 63400: Cost = 0.013144\n",
            "Iteration 63500: Cost = 0.013123\n",
            "Iteration 63600: Cost = 0.013102\n",
            "Iteration 63700: Cost = 0.013081\n",
            "Iteration 63800: Cost = 0.013060\n",
            "Iteration 63900: Cost = 0.013039\n",
            "Iteration 64000: Cost = 0.013018\n",
            "Iteration 64100: Cost = 0.012997\n",
            "Iteration 64200: Cost = 0.012977\n",
            "Iteration 64300: Cost = 0.012956\n",
            "Iteration 64400: Cost = 0.012935\n",
            "Iteration 64500: Cost = 0.012915\n",
            "Iteration 64600: Cost = 0.012895\n",
            "Iteration 64700: Cost = 0.012874\n",
            "Iteration 64800: Cost = 0.012854\n",
            "Iteration 64900: Cost = 0.012834\n",
            "Iteration 65000: Cost = 0.012813\n",
            "Iteration 65100: Cost = 0.012793\n",
            "Iteration 65200: Cost = 0.012773\n",
            "Iteration 65300: Cost = 0.012753\n",
            "Iteration 65400: Cost = 0.012733\n",
            "Iteration 65500: Cost = 0.012713\n",
            "Iteration 65600: Cost = 0.012693\n",
            "Iteration 65700: Cost = 0.012674\n",
            "Iteration 65800: Cost = 0.012654\n",
            "Iteration 65900: Cost = 0.012634\n",
            "Iteration 66000: Cost = 0.012615\n",
            "Iteration 66100: Cost = 0.012595\n",
            "Iteration 66200: Cost = 0.012576\n",
            "Iteration 66300: Cost = 0.012556\n",
            "Iteration 66400: Cost = 0.012537\n",
            "Iteration 66500: Cost = 0.012518\n",
            "Iteration 66600: Cost = 0.012498\n",
            "Iteration 66700: Cost = 0.012479\n",
            "Iteration 66800: Cost = 0.012460\n",
            "Iteration 66900: Cost = 0.012441\n",
            "Iteration 67000: Cost = 0.012422\n",
            "Iteration 67100: Cost = 0.012403\n",
            "Iteration 67200: Cost = 0.012384\n",
            "Iteration 67300: Cost = 0.012365\n",
            "Iteration 67400: Cost = 0.012347\n",
            "Iteration 67500: Cost = 0.012328\n",
            "Iteration 67600: Cost = 0.012309\n",
            "Iteration 67700: Cost = 0.012291\n",
            "Iteration 67800: Cost = 0.012272\n",
            "Iteration 67900: Cost = 0.012254\n",
            "Iteration 68000: Cost = 0.012235\n",
            "Iteration 68100: Cost = 0.012217\n",
            "Iteration 68200: Cost = 0.012199\n",
            "Iteration 68300: Cost = 0.012180\n",
            "Iteration 68400: Cost = 0.012162\n",
            "Iteration 68500: Cost = 0.012144\n",
            "Iteration 68600: Cost = 0.012126\n",
            "Iteration 68700: Cost = 0.012108\n",
            "Iteration 68800: Cost = 0.012090\n",
            "Iteration 68900: Cost = 0.012072\n",
            "Iteration 69000: Cost = 0.012054\n",
            "Iteration 69100: Cost = 0.012036\n",
            "Iteration 69200: Cost = 0.012018\n",
            "Iteration 69300: Cost = 0.012001\n",
            "Iteration 69400: Cost = 0.011983\n",
            "Iteration 69500: Cost = 0.011965\n",
            "Iteration 69600: Cost = 0.011948\n",
            "Iteration 69700: Cost = 0.011930\n",
            "Iteration 69800: Cost = 0.011913\n",
            "Iteration 69900: Cost = 0.011895\n",
            "Iteration 70000: Cost = 0.011878\n",
            "Iteration 70100: Cost = 0.011861\n",
            "Iteration 70200: Cost = 0.011843\n",
            "Iteration 70300: Cost = 0.011826\n",
            "Iteration 70400: Cost = 0.011809\n",
            "Iteration 70500: Cost = 0.011792\n",
            "Iteration 70600: Cost = 0.011775\n",
            "Iteration 70700: Cost = 0.011758\n",
            "Iteration 70800: Cost = 0.011741\n",
            "Iteration 70900: Cost = 0.011724\n",
            "Iteration 71000: Cost = 0.011707\n",
            "Iteration 71100: Cost = 0.011690\n",
            "Iteration 71200: Cost = 0.011673\n",
            "Iteration 71300: Cost = 0.011656\n",
            "Iteration 71400: Cost = 0.011640\n",
            "Iteration 71500: Cost = 0.011623\n",
            "Iteration 71600: Cost = 0.011607\n",
            "Iteration 71700: Cost = 0.011590\n",
            "Iteration 71800: Cost = 0.011574\n",
            "Iteration 71900: Cost = 0.011557\n",
            "Iteration 72000: Cost = 0.011541\n",
            "Iteration 72100: Cost = 0.011524\n",
            "Iteration 72200: Cost = 0.011508\n",
            "Iteration 72300: Cost = 0.011492\n",
            "Iteration 72400: Cost = 0.011475\n",
            "Iteration 72500: Cost = 0.011459\n",
            "Iteration 72600: Cost = 0.011443\n",
            "Iteration 72700: Cost = 0.011427\n",
            "Iteration 72800: Cost = 0.011411\n",
            "Iteration 72900: Cost = 0.011395\n",
            "Iteration 73000: Cost = 0.011379\n",
            "Iteration 73100: Cost = 0.011363\n",
            "Iteration 73200: Cost = 0.011347\n",
            "Iteration 73300: Cost = 0.011331\n",
            "Iteration 73400: Cost = 0.011316\n",
            "Iteration 73500: Cost = 0.011300\n",
            "Iteration 73600: Cost = 0.011284\n",
            "Iteration 73700: Cost = 0.011269\n",
            "Iteration 73800: Cost = 0.011253\n",
            "Iteration 73900: Cost = 0.011237\n",
            "Iteration 74000: Cost = 0.011222\n",
            "Iteration 74100: Cost = 0.011206\n",
            "Iteration 74200: Cost = 0.011191\n",
            "Iteration 74300: Cost = 0.011176\n",
            "Iteration 74400: Cost = 0.011160\n",
            "Iteration 74500: Cost = 0.011145\n",
            "Iteration 74600: Cost = 0.011130\n",
            "Iteration 74700: Cost = 0.011114\n",
            "Iteration 74800: Cost = 0.011099\n",
            "Iteration 74900: Cost = 0.011084\n",
            "Iteration 75000: Cost = 0.011069\n",
            "Iteration 75100: Cost = 0.011054\n",
            "Iteration 75200: Cost = 0.011039\n",
            "Iteration 75300: Cost = 0.011024\n",
            "Iteration 75400: Cost = 0.011009\n",
            "Iteration 75500: Cost = 0.010994\n",
            "Iteration 75600: Cost = 0.010979\n",
            "Iteration 75700: Cost = 0.010964\n",
            "Iteration 75800: Cost = 0.010950\n",
            "Iteration 75900: Cost = 0.010935\n",
            "Iteration 76000: Cost = 0.010920\n",
            "Iteration 76100: Cost = 0.010906\n",
            "Iteration 76200: Cost = 0.010891\n",
            "Iteration 76300: Cost = 0.010876\n",
            "Iteration 76400: Cost = 0.010862\n",
            "Iteration 76500: Cost = 0.010847\n",
            "Iteration 76600: Cost = 0.010833\n",
            "Iteration 76700: Cost = 0.010818\n",
            "Iteration 76800: Cost = 0.010804\n",
            "Iteration 76900: Cost = 0.010790\n",
            "Iteration 77000: Cost = 0.010775\n",
            "Iteration 77100: Cost = 0.010761\n",
            "Iteration 77200: Cost = 0.010747\n",
            "Iteration 77300: Cost = 0.010733\n",
            "Iteration 77400: Cost = 0.010719\n",
            "Iteration 77500: Cost = 0.010704\n",
            "Iteration 77600: Cost = 0.010690\n",
            "Iteration 77700: Cost = 0.010676\n",
            "Iteration 77800: Cost = 0.010662\n",
            "Iteration 77900: Cost = 0.010648\n",
            "Iteration 78000: Cost = 0.010634\n",
            "Iteration 78100: Cost = 0.010620\n",
            "Iteration 78200: Cost = 0.010607\n",
            "Iteration 78300: Cost = 0.010593\n",
            "Iteration 78400: Cost = 0.010579\n",
            "Iteration 78500: Cost = 0.010565\n",
            "Iteration 78600: Cost = 0.010551\n",
            "Iteration 78700: Cost = 0.010538\n",
            "Iteration 78800: Cost = 0.010524\n",
            "Iteration 78900: Cost = 0.010510\n",
            "Iteration 79000: Cost = 0.010497\n",
            "Iteration 79100: Cost = 0.010483\n",
            "Iteration 79200: Cost = 0.010470\n",
            "Iteration 79300: Cost = 0.010456\n",
            "Iteration 79400: Cost = 0.010443\n",
            "Iteration 79500: Cost = 0.010429\n",
            "Iteration 79600: Cost = 0.010416\n",
            "Iteration 79700: Cost = 0.010403\n",
            "Iteration 79800: Cost = 0.010389\n",
            "Iteration 79900: Cost = 0.010376\n",
            "Iteration 80000: Cost = 0.010363\n",
            "Iteration 80100: Cost = 0.010350\n",
            "Iteration 80200: Cost = 0.010337\n",
            "Iteration 80300: Cost = 0.010323\n",
            "Iteration 80400: Cost = 0.010310\n",
            "Iteration 80500: Cost = 0.010297\n",
            "Iteration 80600: Cost = 0.010284\n",
            "Iteration 80700: Cost = 0.010271\n",
            "Iteration 80800: Cost = 0.010258\n",
            "Iteration 80900: Cost = 0.010245\n",
            "Iteration 81000: Cost = 0.010232\n",
            "Iteration 81100: Cost = 0.010219\n",
            "Iteration 81200: Cost = 0.010207\n",
            "Iteration 81300: Cost = 0.010194\n",
            "Iteration 81400: Cost = 0.010181\n",
            "Iteration 81500: Cost = 0.010168\n",
            "Iteration 81600: Cost = 0.010155\n",
            "Iteration 81700: Cost = 0.010143\n",
            "Iteration 81800: Cost = 0.010130\n",
            "Iteration 81900: Cost = 0.010117\n",
            "Iteration 82000: Cost = 0.010105\n",
            "Iteration 82100: Cost = 0.010092\n",
            "Iteration 82200: Cost = 0.010080\n",
            "Iteration 82300: Cost = 0.010067\n",
            "Iteration 82400: Cost = 0.010055\n",
            "Iteration 82500: Cost = 0.010042\n",
            "Iteration 82600: Cost = 0.010030\n",
            "Iteration 82700: Cost = 0.010018\n",
            "Iteration 82800: Cost = 0.010005\n",
            "Iteration 82900: Cost = 0.009993\n",
            "Iteration 83000: Cost = 0.009981\n",
            "Iteration 83100: Cost = 0.009968\n",
            "Iteration 83200: Cost = 0.009956\n",
            "Iteration 83300: Cost = 0.009944\n",
            "Iteration 83400: Cost = 0.009932\n",
            "Iteration 83500: Cost = 0.009920\n",
            "Iteration 83600: Cost = 0.009908\n",
            "Iteration 83700: Cost = 0.009895\n",
            "Iteration 83800: Cost = 0.009883\n",
            "Iteration 83900: Cost = 0.009871\n",
            "Iteration 84000: Cost = 0.009859\n",
            "Iteration 84100: Cost = 0.009847\n",
            "Iteration 84200: Cost = 0.009835\n",
            "Iteration 84300: Cost = 0.009824\n",
            "Iteration 84400: Cost = 0.009812\n",
            "Iteration 84500: Cost = 0.009800\n",
            "Iteration 84600: Cost = 0.009788\n",
            "Iteration 84700: Cost = 0.009776\n",
            "Iteration 84800: Cost = 0.009764\n",
            "Iteration 84900: Cost = 0.009753\n",
            "Iteration 85000: Cost = 0.009741\n",
            "Iteration 85100: Cost = 0.009729\n",
            "Iteration 85200: Cost = 0.009718\n",
            "Iteration 85300: Cost = 0.009706\n",
            "Iteration 85400: Cost = 0.009694\n",
            "Iteration 85500: Cost = 0.009683\n",
            "Iteration 85600: Cost = 0.009671\n",
            "Iteration 85700: Cost = 0.009660\n",
            "Iteration 85800: Cost = 0.009648\n",
            "Iteration 85900: Cost = 0.009637\n",
            "Iteration 86000: Cost = 0.009625\n",
            "Iteration 86100: Cost = 0.009614\n",
            "Iteration 86200: Cost = 0.009603\n",
            "Iteration 86300: Cost = 0.009591\n",
            "Iteration 86400: Cost = 0.009580\n",
            "Iteration 86500: Cost = 0.009569\n",
            "Iteration 86600: Cost = 0.009557\n",
            "Iteration 86700: Cost = 0.009546\n",
            "Iteration 86800: Cost = 0.009535\n",
            "Iteration 86900: Cost = 0.009524\n",
            "Iteration 87000: Cost = 0.009513\n",
            "Iteration 87100: Cost = 0.009501\n",
            "Iteration 87200: Cost = 0.009490\n",
            "Iteration 87300: Cost = 0.009479\n",
            "Iteration 87400: Cost = 0.009468\n",
            "Iteration 87500: Cost = 0.009457\n",
            "Iteration 87600: Cost = 0.009446\n",
            "Iteration 87700: Cost = 0.009435\n",
            "Iteration 87800: Cost = 0.009424\n",
            "Iteration 87900: Cost = 0.009413\n",
            "Iteration 88000: Cost = 0.009402\n",
            "Iteration 88100: Cost = 0.009391\n",
            "Iteration 88200: Cost = 0.009381\n",
            "Iteration 88300: Cost = 0.009370\n",
            "Iteration 88400: Cost = 0.009359\n",
            "Iteration 88500: Cost = 0.009348\n",
            "Iteration 88600: Cost = 0.009337\n",
            "Iteration 88700: Cost = 0.009327\n",
            "Iteration 88800: Cost = 0.009316\n",
            "Iteration 88900: Cost = 0.009305\n",
            "Iteration 89000: Cost = 0.009295\n",
            "Iteration 89100: Cost = 0.009284\n",
            "Iteration 89200: Cost = 0.009273\n",
            "Iteration 89300: Cost = 0.009263\n",
            "Iteration 89400: Cost = 0.009252\n",
            "Iteration 89500: Cost = 0.009242\n",
            "Iteration 89600: Cost = 0.009231\n",
            "Iteration 89700: Cost = 0.009221\n",
            "Iteration 89800: Cost = 0.009210\n",
            "Iteration 89900: Cost = 0.009200\n",
            "Iteration 90000: Cost = 0.009189\n",
            "Iteration 90100: Cost = 0.009179\n",
            "Iteration 90200: Cost = 0.009168\n",
            "Iteration 90300: Cost = 0.009158\n",
            "Iteration 90400: Cost = 0.009148\n",
            "Iteration 90500: Cost = 0.009138\n",
            "Iteration 90600: Cost = 0.009127\n",
            "Iteration 90700: Cost = 0.009117\n",
            "Iteration 90800: Cost = 0.009107\n",
            "Iteration 90900: Cost = 0.009096\n",
            "Iteration 91000: Cost = 0.009086\n",
            "Iteration 91100: Cost = 0.009076\n",
            "Iteration 91200: Cost = 0.009066\n",
            "Iteration 91300: Cost = 0.009056\n",
            "Iteration 91400: Cost = 0.009046\n",
            "Iteration 91500: Cost = 0.009036\n",
            "Iteration 91600: Cost = 0.009026\n",
            "Iteration 91700: Cost = 0.009016\n",
            "Iteration 91800: Cost = 0.009006\n",
            "Iteration 91900: Cost = 0.008996\n",
            "Iteration 92000: Cost = 0.008986\n",
            "Iteration 92100: Cost = 0.008976\n",
            "Iteration 92200: Cost = 0.008966\n",
            "Iteration 92300: Cost = 0.008956\n",
            "Iteration 92400: Cost = 0.008946\n",
            "Iteration 92500: Cost = 0.008936\n",
            "Iteration 92600: Cost = 0.008926\n",
            "Iteration 92700: Cost = 0.008916\n",
            "Iteration 92800: Cost = 0.008907\n",
            "Iteration 92900: Cost = 0.008897\n",
            "Iteration 93000: Cost = 0.008887\n",
            "Iteration 93100: Cost = 0.008877\n",
            "Iteration 93200: Cost = 0.008868\n",
            "Iteration 93300: Cost = 0.008858\n",
            "Iteration 93400: Cost = 0.008848\n",
            "Iteration 93500: Cost = 0.008839\n",
            "Iteration 93600: Cost = 0.008829\n",
            "Iteration 93700: Cost = 0.008819\n",
            "Iteration 93800: Cost = 0.008810\n",
            "Iteration 93900: Cost = 0.008800\n",
            "Iteration 94000: Cost = 0.008791\n",
            "Iteration 94100: Cost = 0.008781\n",
            "Iteration 94200: Cost = 0.008772\n",
            "Iteration 94300: Cost = 0.008762\n",
            "Iteration 94400: Cost = 0.008753\n",
            "Iteration 94500: Cost = 0.008743\n",
            "Iteration 94600: Cost = 0.008734\n",
            "Iteration 94700: Cost = 0.008725\n",
            "Iteration 94800: Cost = 0.008715\n",
            "Iteration 94900: Cost = 0.008706\n",
            "Iteration 95000: Cost = 0.008696\n",
            "Iteration 95100: Cost = 0.008687\n",
            "Iteration 95200: Cost = 0.008678\n",
            "Iteration 95300: Cost = 0.008669\n",
            "Iteration 95400: Cost = 0.008659\n",
            "Iteration 95500: Cost = 0.008650\n",
            "Iteration 95600: Cost = 0.008641\n",
            "Iteration 95700: Cost = 0.008632\n",
            "Iteration 95800: Cost = 0.008622\n",
            "Iteration 95900: Cost = 0.008613\n",
            "Iteration 96000: Cost = 0.008604\n",
            "Iteration 96100: Cost = 0.008595\n",
            "Iteration 96200: Cost = 0.008586\n",
            "Iteration 96300: Cost = 0.008577\n",
            "Iteration 96400: Cost = 0.008568\n",
            "Iteration 96500: Cost = 0.008559\n",
            "Iteration 96600: Cost = 0.008550\n",
            "Iteration 96700: Cost = 0.008541\n",
            "Iteration 96800: Cost = 0.008532\n",
            "Iteration 96900: Cost = 0.008523\n",
            "Iteration 97000: Cost = 0.008514\n",
            "Iteration 97100: Cost = 0.008505\n",
            "Iteration 97200: Cost = 0.008496\n",
            "Iteration 97300: Cost = 0.008487\n",
            "Iteration 97400: Cost = 0.008478\n",
            "Iteration 97500: Cost = 0.008469\n",
            "Iteration 97600: Cost = 0.008460\n",
            "Iteration 97700: Cost = 0.008452\n",
            "Iteration 97800: Cost = 0.008443\n",
            "Iteration 97900: Cost = 0.008434\n",
            "Iteration 98000: Cost = 0.008425\n",
            "Iteration 98100: Cost = 0.008416\n",
            "Iteration 98200: Cost = 0.008408\n",
            "Iteration 98300: Cost = 0.008399\n",
            "Iteration 98400: Cost = 0.008390\n",
            "Iteration 98500: Cost = 0.008382\n",
            "Iteration 98600: Cost = 0.008373\n",
            "Iteration 98700: Cost = 0.008364\n",
            "Iteration 98800: Cost = 0.008356\n",
            "Iteration 98900: Cost = 0.008347\n",
            "Iteration 99000: Cost = 0.008339\n",
            "Iteration 99100: Cost = 0.008330\n",
            "Iteration 99200: Cost = 0.008321\n",
            "Iteration 99300: Cost = 0.008313\n",
            "Iteration 99400: Cost = 0.008304\n",
            "Iteration 99500: Cost = 0.008296\n",
            "Iteration 99600: Cost = 0.008287\n",
            "Iteration 99700: Cost = 0.008279\n",
            "Iteration 99800: Cost = 0.008270\n",
            "Iteration 99900: Cost = 0.008262\n",
            "Iteration 99999: Cost = 0.008254\n",
            "\n",
            "Final parameters:\n",
            "w: [38.51304248 18.83386869], b: -2.8176836626325836\n",
            "Final cost: 0.008254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A simple assertion test for gradient descent Function:"
      ],
      "metadata": {
        "id": "eqyqsR7TTFdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple assertion test for gradient_descent\n",
        "def test_gradient_descent():\n",
        "  X = np.array([[0.1, 0.2], [-0.1, 0.1]]) # Shape (2, 2)\n",
        "  y = np.array([1, 0]) # Shape (2,)\n",
        "  w = np.zeros(X.shape[1]) # Shape (2,)\n",
        "  b = 0.0 # Scalar\n",
        "  alpha = 0.1 # Learning rate\n",
        "  n_iter = 100 # Number of iterations\n",
        "  # Run gradient descent\n",
        "  w_out, b_out, cost_history, _ = gradient_descent(X, y, w, b, alpha, n_iter, show_cost=False,\n",
        "  show_params=False)\n",
        "  # Assertions\n",
        "  assert len(cost_history) == n_iter, \"Cost history length does not match the number of iterations\"\n",
        "  assert w_out.shape == w.shape, \"Shape of output weights does not match the initial weights\"\n",
        "  assert isinstance(b_out, float), \"Bias output is not a float\"\n",
        "  assert cost_history[-1] < cost_history[0], \"Cost did not decrease over iterations\"\n",
        "  print(\"All tests passed!\")\n",
        "# Run the test\n",
        "test_gradient_descent()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPKTCjMpSs1B",
        "outputId": "23d1cd5c-147e-4b4b-e4bd-0771bbee3aca"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task To Do:\n",
        "• Implement the prediction Function by completing the code or writing your own function.\n",
        "• Make sure you pass the test case."
      ],
      "metadata": {
        "id": "MJga_wRRTnKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def prediction(X, w, b, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Predicts binary outcomes for given input features based on logistic regression parameters.\n",
        "    \"\"\"\n",
        "    # Compute the predicted probabilities using the logistic function\n",
        "    y_test_prob = 1 / (1 + np.exp(-(np.dot(X, w) + b)))\n",
        "\n",
        "    # Classify based on the threshold\n",
        "    y_pred = (y_test_prob >= threshold).astype(int)\n",
        "\n",
        "    return y_pred\n"
      ],
      "metadata": {
        "id": "xht_k_2wTGhl"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A simple assertion test for Prediction Function:"
      ],
      "metadata": {
        "id": "kityjV5ZUJXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_prediction():\n",
        "  X_test = np.array([[0.5, 1.0], [1.5, -0.5], [-0.5, -1.0]]) # Shape (3, 2)\n",
        "  w_test = np.array([1.0, -1.0]) # Shape (2,)\n",
        "  b_test = 0.0 # Scalar bias\n",
        "  threshold = 0.5 # Default threshold\n",
        "  # Updated expected output\n",
        "  expected_output = np.array([0, 1, 1])\n",
        "  # Call the prediction function\n",
        "  y_pred = prediction(X_test, w_test, b_test, threshold)\n",
        "  # Assert that the output matches the expected output\n",
        "  assert np.array_equal(y_pred, expected_output), f\"Expected {expected_output}, but got {y_pred}\"\n",
        "  print(\"Test passed!\")\n",
        "test_prediction()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YtGa7Q6UIGM",
        "outputId": "d64acff7-bfba-4c54-8050-6644a5bfc12e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate_classification(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Computes the confusion matrix, precision, recall, and F1-score for binary classification.\n",
        "    \"\"\"\n",
        "    # Initialize confusion matrix components\n",
        "    TP = np.sum((y_true == 1) & (y_pred == 1))  # True Positives\n",
        "    TN = np.sum((y_true == 0) & (y_pred == 0))  # True Negatives\n",
        "    FP = np.sum((y_true == 0) & (y_pred == 1))  # False Positives\n",
        "    FN = np.sum((y_true == 1) & (y_pred == 0))  # False Negatives\n",
        "\n",
        "    # Confusion matrix\n",
        "    confusion_matrix = np.array([[TN, FP],\n",
        "                                 [FN, TP]])\n",
        "\n",
        "    # Precision, recall, and F1-score\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0.0 else 0.0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0.0 else 0.0\n",
        "    f1_score = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0.0 else 0.0\n",
        "\n",
        "    # Metrics dictionary\n",
        "    metrics = {\n",
        "        \"confusion_matrix\": confusion_matrix,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1_score\n",
        "    }\n",
        "    return metrics\n"
      ],
      "metadata": {
        "id": "sthikKNfUbum"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Putting Helper Function to Action - Sigmoid Regression for the dataset:\n",
        "Dataset Used: \"pima-indians-diabetes.data.csv\"\n",
        "1. Some Basic Data Operation, Loading, Analysis and Cleaning:"
      ],
      "metadata": {
        "id": "6et7KwCSVz6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dataset URL\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "\n",
        "# Column names\n",
        "columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
        "\n",
        "# Load the dataset\n",
        "data_pima_diabetes = pd.read_csv(url, names=columns)\n",
        "\n",
        "# Check the first few rows\n",
        "print(data_pima_diabetes.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTpTNcmMVzSo",
        "outputId": "017f356e-0504-4b9c-9ce3-f4687f06f40b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0            6      148             72             35        0  33.6   \n",
            "1            1       85             66             29        0  26.6   \n",
            "2            8      183             64              0        0  23.3   \n",
            "3            1       89             66             23       94  28.1   \n",
            "4            0      137             40             35      168  43.1   \n",
            "\n",
            "   DiabetesPedigreeFunction  Age  Outcome  \n",
            "0                     0.627   50        1  \n",
            "1                     0.351   31        0  \n",
            "2                     0.672   32        1  \n",
            "3                     0.167   21        0  \n",
            "4                     2.288   33        1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some Basic Data Cleaning:"
      ],
      "metadata": {
        "id": "8yDkHBmoWQbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data cleaning\n",
        "columns_to_clean = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
        "\n",
        "# Replace 0 with NaN in selected columns\n",
        "data_pima_diabetes[columns_to_clean] = data_pima_diabetes[columns_to_clean].replace(0, np.nan)\n",
        "\n",
        "# Fill NaN with median values\n",
        "data_pima_diabetes.fillna(data_pima_diabetes.median(), inplace=True)\n",
        "\n",
        "# Check dataset info\n",
        "data_pima_diabetes.info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzMSwPU-WPdD",
        "outputId": "b87b5f46-9a73-4fdb-da78-766f961c8925"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 768 entries, 0 to 767\n",
            "Data columns (total 9 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Pregnancies               768 non-null    int64  \n",
            " 1   Glucose                   768 non-null    float64\n",
            " 2   BloodPressure             768 non-null    float64\n",
            " 3   SkinThickness             768 non-null    float64\n",
            " 4   Insulin                   768 non-null    float64\n",
            " 5   BMI                       768 non-null    float64\n",
            " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
            " 7   Age                       768 non-null    int64  \n",
            " 8   Outcome                   768 non-null    int64  \n",
            "dtypes: float64(6), int64(3)\n",
            "memory usage: 54.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Test Split and Standard Scaling of the Data:"
      ],
      "metadata": {
        "id": "QmhVkjdYWqvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X = data_pima_diabetes.drop(columns=['Outcome']).values\n",
        "y = data_pima_diabetes['Outcome'].values\n",
        "\n",
        "# Split dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Check the shape of the scaled data\n",
        "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
        "print(\"X_test_scaled shape:\", X_test_scaled.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zYve_-MWj_d",
        "outputId": "e6f47555-1154-4b38-e2d8-f8a5078e94af"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_scaled shape: (614, 8)\n",
            "X_test_scaled shape: (154, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training of the Sigmoid Regression:"
      ],
      "metadata": {
        "id": "klRYoAJeWyCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize parameters\n",
        "w = np.zeros(X_train_scaled.shape[1])\n",
        "b = 0.0\n",
        "alpha = 0.1\n",
        "n_iter = 1000\n",
        "# Train model\n",
        "\n",
        "print(\"\\nTraining Logistic Regression Model:\")\n",
        "w, b, cost_history,params_history = gradient_descent(X_train_scaled, y_train, w, b, alpha, n_iter,\n",
        "show_cost=True, show_params=False)\n",
        "# Plot cost history\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.plot(cost_history)\n",
        "plt.xlabel(\"Iteration\", fontsize=14)\n",
        "plt.ylabel(\"Cost\", fontsize=14)\n",
        "plt.title(\"Cost vs Iteration\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "CJyhdvRIWxWw",
        "outputId": "afbf4583-9ae0-47ed-df5a-60b15f12f888"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Logistic Regression Model:\n",
            "Iteration 0: Cost = 0.676575\n",
            "Iteration 100: Cost = 0.465441\n",
            "Iteration 200: Cost = 0.455913\n",
            "Iteration 300: Cost = 0.453874\n",
            "Iteration 400: Cost = 0.453316\n",
            "Iteration 500: Cost = 0.453148\n",
            "Iteration 600: Cost = 0.453096\n",
            "Iteration 700: Cost = 0.453079\n",
            "Iteration 800: Cost = 0.453074\n",
            "Iteration 900: Cost = 0.453072\n",
            "Iteration 999: Cost = 0.453071\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Did the Model Overfitt or Underfitt?"
      ],
      "metadata": {
        "id": "y9oIp6GRXJPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test model\n",
        "y_train_pred = prediction(X_train_scaled, w, b)\n",
        "y_test_pred = prediction(X_test_scaled, w, b)\n",
        "# Evaluate train and test performance\n",
        "train_cost = costfunction_logreg(X_train_scaled, y_train, w, b)\n",
        "test_cost = costfunction_logreg(X_test_scaled, y_test, w, b)\n",
        "print(f\"\\nTrain Loss (Cost): {train_cost:.4f}\")\n",
        "print(f\"Test Loss (Cost): {test_cost:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URC5Rk-2XHyh",
        "outputId": "1c7cd48a-1b67-454e-a7e5-5f846d14727f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Loss (Cost): 0.4531\n",
            "Test Loss (Cost): 0.5146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How well my model did?"
      ],
      "metadata": {
        "id": "m0-Y5ri0Xd8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy on test data\n",
        "test_accuracy = np.mean(y_test_pred == y_test) * 100\n",
        "print(f\"\\nTest Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "# Evaluation\n",
        "metrics = evaluate_classification(y_test, y_test_pred)\n",
        "confusion_matrix = metrics[\"confusion_matrix\"]\n",
        "precision = metrics[\"precision\"]\n",
        "recall = metrics[\"recall\"]\n",
        "f1_score = metrics[\"f1_score\"]\n",
        "\n",
        "print(f\"\\nConfusion Matrix:\\n{confusion_matrix}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1_score:.4f}\")\n",
        "\n",
        "# Optional - Visualizing the Confusion Matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "ax.imshow(confusion_matrix, cmap='Blues')\n",
        "ax.grid(False)\n",
        "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
        "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
        "ax.set_ylim(1.5, -0.5)\n",
        "\n",
        "# Add text annotations\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        value = confusion_matrix[i, j]\n",
        "        # Choose text color based on cell value (dark or light background)\n",
        "        text_color = 'white' if value > confusion_matrix.max()/2 else 'black'\n",
        "        ax.text(j, i, f'{value}\\n({value/len(y_test)*100:.1f}%)',\n",
        "                ha='center', va='center', color=text_color, fontsize=12, fontweight='bold')\n",
        "\n",
        "# Add title\n",
        "ax.set_title('Confusion Matrix', fontsize=14, fontweight='bold', pad=20)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "id": "V-1kRGgSXZYD",
        "outputId": "a7fc668c-ba30-4d96-fcae-3b086edd276c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy: 70.78%\n",
            "\n",
            "Confusion Matrix:\n",
            "[[82 18]\n",
            " [27 27]]\n",
            "Precision: 0.6000\n",
            "Recall: 0.5000\n",
            "F1-Score: 0.5455\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}